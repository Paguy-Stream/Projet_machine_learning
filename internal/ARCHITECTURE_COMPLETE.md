# üìò Guide Complet du Projet - Pr√©dicteur de Salaires Data Jobs

> **Version 2.1** - F√©vrier 2026  
> Application Streamlit d'estimation salariale bas√©e sur 5,868 offres HelloWork

---

## üìã Table des mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Architecture du projet](#architecture-du-projet)
3. [Structure des fichiers](#structure-des-fichiers)
4. [Modules principaux](#modules-principaux)
5. [Configuration et d√©ploiement](#configuration-et-d√©ploiement)
6. [Guide de d√©veloppement](#guide-de-d√©veloppement)
7. [D√©pannage](#d√©pannage)
8. [Feuille de route](#feuille-de-route)

---

## üéØ Vue d'ensemble

### Objectif du projet

Application web interactive permettant d'estimer les salaires dans les m√©tiers de la Data √† partir d'un profil utilisateur, bas√©e sur l'analyse de **5,868 offres d'emploi** collect√©es sur HelloWork en janvier 2026.

### Fonctionnalit√©s principales

1. **üîÆ Pr√©diction salariale** : Estimation personnalis√©e bas√©e sur profil, localisation, comp√©tences
2. **üìä Analyse du march√©** : Visualisations interactives, tendances, comparaisons
3. **üéì Feuille de route carri√®re** : Roadmap personnalis√©e, projections salariales, transitions de r√¥le
4. **üí° Insights dynamiques** : Multiplicateurs salariaux calcul√©s en temps r√©el depuis les donn√©es

### Technologies utilis√©es

| Cat√©gorie | Technologies |
|-----------|-------------|
| **Frontend** | Streamlit 1.31.0, Plotly 5.18.0, Matplotlib 3.8.2 |
| **ML/Data** | XGBoost 2.0.3, Scikit-learn 1.3.2, Pandas 2.1.4, NumPy 1.26.2 |
| **Viz avanc√©e** | Seaborn 0.13.0, SHAP 0.44.0 |
| **Tests** | Pytest 7.4.3, Coverage 4.1.0 |
| **Cloud** | Streamlit Cloud, GitHub |

### M√©triques du mod√®le

```
Mod√®le       : XGBoost v7 optimis√©
Dataset      : 2,681 √©chantillons Data (train), 5,868 total
R¬≤           : 0.337
MAE          : 5,163 ‚Ç¨
RMSE         : 6,969 ‚Ç¨
Pr√©cision    : 73.7% (¬±15%), 83.8% (¬±20%)
Stabilit√©    : 0.995 (cross-validation)
Overfitting  : 0.140 (contr√¥l√©)
```

---

## üèóÔ∏è Architecture du projet

### Architecture globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     STREAMLIT FRONTEND                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   Accueil    ‚îÇ  ‚îÇ  Pr√©diction  ‚îÇ  ‚îÇ    March√©    ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   Carri√®re   ‚îÇ  ‚îÇ    Debug     ‚îÇ  ‚îÇ   (Autres)   ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COUCHE LOGIQUE                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ   internal/  ‚îÇ  ‚îÇ    utils/    ‚îÇ  ‚îÇ   scripts/   ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  (modules)   ‚îÇ  ‚îÇ  (config)    ‚îÇ  ‚îÇ  (nettoyage) ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    COUCHE DONN√âES                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  output/     ‚îÇ  ‚îÇ   models/    ‚îÇ  ‚îÇ    data/     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  (dataset)   ‚îÇ  ‚îÇ  (XGBoost)   ‚îÇ  ‚îÇ  (scripts)   ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flux de donn√©es

```
Donn√©es brutes (HelloWork)
         ‚îÇ
         ‚ñº
Nettoyage (scripts/data_cleaning*.py)
         ‚îÇ
         ‚ñº
Dataset enrichi (output/hellowork_cleaned_complete.csv)
         ‚îÇ
         ‚ñº
Feature Engineering (utils/feature_engineer.py)
         ‚îÇ
         ‚ñº
Mod√®le XGBoost (models/best_model_XGBoost_fixed.pkl)
         ‚îÇ
         ‚ñº
API Pr√©diction (utils/model_utils.py)
         ‚îÇ
         ‚ñº
Interface Streamlit (pages/*.py)
         ‚îÇ
         ‚ñº
Utilisateur final
```

---

## üìÅ Structure des fichiers

### Arborescence compl√®te

```
Projet_machine_learning/
‚îÇ
‚îú‚îÄ‚îÄ 01_Accueil.py                      # Page d'accueil principale ‚≠ê
‚îÇ
‚îú‚îÄ‚îÄ pages/                             # Pages Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ 01_Prediction.py              # Pr√©diction salariale
‚îÇ   ‚îú‚îÄ‚îÄ 02_Marche.py                  # Analyse du march√©
‚îÇ   ‚îú‚îÄ‚îÄ 03_Carriere.py                # Feuille de route carri√®re
‚îÇ   ‚îî‚îÄ‚îÄ 99_Debug.py                   # Outils de debug
‚îÇ
‚îú‚îÄ‚îÄ internal/                          # Modules de logique m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ prediction_display_impl.py    # Affichage pr√©diction
‚îÇ   ‚îú‚îÄ‚îÄ prediction_action_impl.py     # Actions pr√©diction
‚îÇ   ‚îú‚îÄ‚îÄ prediction_comparisons.py     # Comparaisons
‚îÇ   ‚îú‚îÄ‚îÄ market_analysis_impl.py       # Analyses march√©
‚îÇ   ‚îú‚îÄ‚îÄ market_filters_impl.py        # Filtres march√©
‚îÇ   ‚îú‚îÄ‚îÄ market_export_impl.py         # Export donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ career_analysis.py            # Analyse carri√®re
‚îÇ   ‚îú‚îÄ‚îÄ career_roadmap.py             # Roadmap comp√©tences
‚îÇ   ‚îú‚îÄ‚îÄ career_transitions.py         # Transitions r√¥les
‚îÇ   ‚îî‚îÄ‚îÄ career_export.py              # Export carri√®re
‚îÇ
‚îú‚îÄ‚îÄ utils/                             # Utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ config.py                     # Configuration centrale ‚öôÔ∏è
‚îÇ   ‚îú‚îÄ‚îÄ model_utils.py                # Gestion mod√®le ML
‚îÇ   ‚îî‚îÄ‚îÄ feature_engineer.py           # Feature engineering
‚îÇ
‚îú‚îÄ‚îÄ models/                            # Mod√®les ML
‚îÇ   ‚îú‚îÄ‚îÄ best_model_XGBoost_fixed.pkl  # Mod√®le XGBoost v7
‚îÇ   ‚îú‚îÄ‚îÄ test_data.pkl                 # Donn√©es de test
‚îÇ   ‚îî‚îÄ‚îÄ modeling_report_v7.json       # Rapport performance
‚îÇ
‚îú‚îÄ‚îÄ output/                            # Donn√©es nettoy√©es
‚îÇ   ‚îú‚îÄ‚îÄ hellowork_cleaned_complete.csv # Dataset principal (52 MB)
‚îÇ   ‚îú‚îÄ‚îÄ test_data.pkl                 # Donn√©es test
‚îÇ   ‚îî‚îÄ‚îÄ analysis_complete/            # Analyses compl√®tes
‚îÇ       ‚îî‚îÄ‚îÄ modeling_v7_improved/
‚îÇ           ‚îî‚îÄ‚îÄ modeling_report_v7.json
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Scripts de collecte
‚îÇ   ‚îî‚îÄ‚îÄ hellowork_scraper.py          # Web scraper
‚îÇ
‚îú‚îÄ‚îÄ scripts/                           # Scripts d'analyse
‚îÇ   ‚îú‚îÄ‚îÄ data_cleaning_step*.py        # Nettoyage (5 √©tapes)
‚îÇ   ‚îî‚îÄ‚îÄ modeling_refactored.py        # Entra√Ænement mod√®le
‚îÇ
‚îú‚îÄ‚îÄ tests/                             # Tests unitaires
‚îÇ   ‚îî‚îÄ‚îÄ test_*.py                     # 99 tests (73% coverage)
‚îÇ
‚îú‚îÄ‚îÄ docs/                              # Documentation
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md               # Ce fichier
‚îÇ   ‚îú‚îÄ‚îÄ GUIDE_GITHUB.md               # Guide Git/GitHub
‚îÇ   ‚îî‚îÄ‚îÄ GUIDE_FIX_STREAMLIT_CLOUD.md  # D√©pannage d√©ploiement
‚îÇ
‚îú‚îÄ‚îÄ images/                            # Assets visuels
‚îÇ   ‚îú‚îÄ‚îÄ gift_accueil.gif
‚îÇ   ‚îú‚îÄ‚îÄ gift_pred.gif
‚îÇ   ‚îú‚îÄ‚îÄ gift_pred_02.gif
‚îÇ   ‚îú‚îÄ‚îÄ gift_marche.gif
‚îÇ   ‚îî‚îÄ‚îÄ gift_carriere.gif
‚îÇ
‚îú‚îÄ‚îÄ .streamlit/                        # Config Streamlit
‚îÇ   ‚îî‚îÄ‚îÄ config.toml
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                   # D√©pendances Python
‚îú‚îÄ‚îÄ .gitignore                         # Exclusions Git
‚îú‚îÄ‚îÄ .gitattributes                     # Attributs Git (LFS)
‚îú‚îÄ‚îÄ README.md                          # Documentation principale
‚îî‚îÄ‚îÄ DEBUG_PATHS.py                     # Outil de debug chemins
```

### Statistiques du projet

```
Fichiers Python        : ~45
Lignes de code         : ~9,500
Tests                  : 99 (73% coverage)
Taille dataset         : 52 MB (5,868 offres)
Taille mod√®le          : 67 KB
Pages Streamlit        : 4
Modules internes       : 10
```

---

## üß© Modules principaux

### 1. Configuration (`utils/config.py`)

**R√¥le** : Configuration centralis√©e de l'application

```python
class Config:
    # Chemins dynamiques
    BASE_DIR = Path(__file__).parent.parent
    DATA_PATH = BASE_DIR / "output" / "hellowork_cleaned_complete.csv"
    MODEL_PATH = BASE_DIR / "models" / "best_model_XGBoost_fixed.pkl"
    
    # M√©triques mod√®le
    MODEL_INFO = {
        'r2_score': 0.337,
        'mae': 5163,
        'precision_15': 73.7
    }
    
    # √ânum√©rations
    JOB_TYPES = ["Data Analyst", "Data Scientist", ...]
    CITIES = ["Paris", "Lyon", "Toulouse", ...]
    SECTORS = ["Tech", "Banque", "Finance", ...]
    
    # Multiplicateurs dynamiques
    @classmethod
    def get_city_multiplier(cls, city: str) -> float:
        """Calcule multiplicateur salarial par ville"""
        ...
```

**Fonctionnalit√©s cl√©s** :
- ‚úÖ Chemins de fichiers dynamiques (compatible Streamlit Cloud)
- ‚úÖ Multiplicateurs calcul√©s depuis le dataset en temps r√©el
- ‚úÖ Cache des valeurs pour performances
- ‚úÖ Exports pour tous les modules

---

### 2. Utilitaires ML (`utils/model_utils.py`)

**R√¥le** : Gestion du mod√®le XGBoost et calculs ML

```python
class ModelUtils:
    """Gestionnaire du mod√®le XGBoost"""
    
    def predict(self, profile: Dict) -> Dict:
        """Pr√©diction salariale"""
        features = self._prepare_features(profile)
        prediction = self.model.predict(features)
        return {
            'prediction': float(prediction),
            'confidence': self._calculate_confidence(features),
            'shap_values': self._get_shap_values(features)
        }
    
    def get_real_market_data(self) -> np.ndarray:
        """Donn√©es salariales du march√© r√©el"""
        ...

class CalculationUtils:
    """Calculs statistiques et utilitaires"""
    
    @staticmethod
    def get_percentile_real(salary: float, market_data: np.ndarray) -> float:
        """Calcule le percentile d'un salaire"""
        ...
    
    @staticmethod
    def calculate_skills_count_from_profile(skills: Dict) -> int:
        """Compte les comp√©tences d'un profil"""
        ...

class ChartUtils:
    """Cr√©ation de graphiques Plotly"""
    
    @staticmethod
    def create_salary_gauge(prediction: float, median: float, ...) -> go.Figure:
        """Jauge de positionnement salarial"""
        ...
```

**Fonctionnalit√©s** :
- ‚úÖ Chargement et gestion du mod√®le XGBoost
- ‚úÖ Pr√©dictions avec intervalles de confiance
- ‚úÖ Analyse SHAP (explicabilit√©)
- ‚úÖ Calculs de percentiles et statistiques
- ‚úÖ G√©n√©ration de graphiques Plotly

---

### 3. Feature Engineering (`utils/feature_engineer.py`)

**R√¥le** : Transformation des donn√©es brutes en features ML

```python
class FeatureEngineer:
    """Ing√©nierie des features pour le mod√®le"""
    
    def prepare_features(self, raw_profile: Dict) -> np.ndarray:
        """
        Transforme un profil utilisateur en features ML
        
        Steps:
        1. Extraction features de base
        2. Encoding cat√©gorielles (one-hot)
        3. Scaling num√©riques (robust scaler)
        4. Features d√©riv√©es
        """
        features = self._extract_base_features(raw_profile)
        features = self._encode_categorical(features)
        features = self._scale_numerical(features)
        features = self._add_derived_features(features)
        return features
    
    def _extract_base_features(self, profile: Dict) -> Dict:
        """Extraction des features de base"""
        return {
            'experience_final': profile['experience'],
            'location_final': profile['location'],
            'sector_clean': profile['sector'],
            'skills_count': self._count_skills(profile),
            'technical_score': self._calculate_tech_score(profile),
            ...
        }
```

**Features g√©r√©es** (29 au total) :
- Num√©riques : exp√©rience, salaire, nombre de comp√©tences
- Cat√©gorielles : type de poste, ville, secteur, niveau d'√©tudes
- Binaires : t√©l√©travail, avantages, comp√©tences sp√©cifiques
- D√©riv√©es : score technique, complexit√©, mots-cl√©s

---

### 4. Pages Streamlit

#### üìÑ **01_Accueil.py**

```python
def main():
    """Page d'accueil avec m√©triques et navigation"""
    
    # Initialisation
    config, model_utils = initialize_app()
    data = load_application_data()
    
    # Sidebar
    render_sidebar(data, config)
    
    # Hero section avec CTA
    render_hero_section(config)
    
    # M√©triques cl√©s (4 colonnes)
    render_key_metrics(data, config)
    
    # M√©thodologie (4 √©tapes)
    render_methodology_section()
    
    # Visualisations
    render_salary_distribution(data['test_salaries'])
    render_top_jobs(data['dataset'])
    
    # Navigation (3 cards)
    render_navigation_cards()
```

**Widgets avec cl√©s uniques** :
- `sidebar_btn_report` : Bouton rapport
- `hero_btn_prediction` : CTA principal
- `nav_btn_prediction`, `nav_btn_market`, `nav_btn_career` : Navigation

---

#### üîÆ **pages/01_Prediction.py**

```python
def main():
    """Page de pr√©diction salariale"""
    
    # Initialisation
    model_utils, real_market_data, market_stats = initialize_prediction_page()
    
    # Formulaire de profil
    profile_data = render_prediction_form()
    
    if profile_data:
        # Pr√©diction
        result = model_utils.predict(profile_data)
        
        # Affichage r√©sultats
        render_results(model_utils, real_market_data, market_stats)
        
        # Sections :
        # 1. R√©sultat principal + confiance
        # 2. Positionnement march√© (jauge + percentile)
        # 3. Distribution march√©
        # 4. Analyse SHAP (top 10 features)
        # 5. Comparaisons (secteur, exp√©rience, ville)
        # 6. Impact des comp√©tences
```

**Modules utilis√©s** :
- `prediction_display_impl.py` : Affichage
- `prediction_action_impl.py` : Actions (export, reset)
- `prediction_comparisons.py` : Comparaisons

---

#### üìä **pages/02_Marche.py**

```python
def main():
    """Page d'analyse du march√© Data"""
    
    # Chargement donn√©es
    market_data = load_market_data()
    
    # Filtres sidebar
    filtered_data, filters_info = render_sidebar_filters(market_data)
    
    # Insights (3 colonnes)
    render_key_insights(filtered_data)
    
    # Onglets d'analyse (6 tabs)
    tabs = st.tabs([
        "üîç Vue d'ensemble",
        "üíº Postes & Secteurs",
        "üåç G√©ographie",
        "üõ†Ô∏è Comp√©tences",
        "üîó Combinaisons",
        "üìä Benchmark"
    ])
    
    # Export et navigation
    render_export_and_navigation(filtered_data, total_size, filters_info)
```

**Modules utilis√©s** :
- `market_filters_impl.py` : 8 filtres avec cl√©s uniques
- `market_analysis_impl.py` : Graphiques et analyses
- `market_export_impl.py` : Export CSV/JSON + 4 boutons navigation

---

#### üéì **pages/03_Carriere.py**

```python
def main():
    """Feuille de route carri√®re personnalis√©e"""
    
    # Initialisation
    model_utils, df_final, real_market_data, market_median = initialize_career_page()
    
    # Formulaire profil (18 widgets avec cl√©s)
    profile_data = render_profile_form()
    
    if profile_data:
        # Pr√©diction de base
        base_salary, percentile, base_pred = process_career_profile(...)
        
        # Analyses (8 sections)
        render_scorecard(...)                    # Scorecard 4 m√©triques
        render_positioning_diagnosis(...)        # Diagnostic positionnement
        render_roadmap_section(...)              # Roadmap comp√©tences
        render_effort_impact_matrix(...)         # Matrice effort/impact
        render_transitions_analysis(...)         # Transitions de r√¥le
        render_salary_projection(...)            # Projection 10 ans (3 sc√©narios)
        render_negotiation_simulator(...)        # Simulateur n√©gociation
        render_export_section(...)               # Export PDF/JSON
```

**Modules utilis√©s** :
- `career_analysis.py` : Scorecard et diagnostic
- `career_roadmap.py` : Roadmap et matrice
- `career_transitions.py` : Transitions et projections
- `career_export.py` : N√©gociation et export

**Cl√©s uniques des widgets** (18 total) :
```python
# Section professionnelle (6)
"career_job_type", "career_experience", "career_location"
"career_sector", "career_education", "career_telework"

# Comp√©tences (11)
"career_skill_python", "career_skill_sql", "career_skill_r"
"career_skill_tableau", "career_skill_powerbi", "career_skill_aws"
"career_skill_azure", "career_skill_spark", "career_skill_ml"
"career_skill_dl", "career_skill_etl"

# Submit (pas de cl√© - g√©r√© automatiquement)
```

---

## ‚öôÔ∏è Configuration et d√©ploiement

### Configuration locale

#### 1. Installation

```bash
# Cloner le repository
git clone https://github.com/Paguy-Stream/Projet_machine_learning.git
cd Projet_machine_learning

# Cr√©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Installer d√©pendances
pip install -r requirements.txt
```

#### 2. Structure des donn√©es requise

```
Projet_machine_learning/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ best_model_XGBoost_fixed.pkl  ‚Üê OBLIGATOIRE (67 KB)
‚îî‚îÄ‚îÄ output/
    ‚îî‚îÄ‚îÄ hellowork_cleaned_complete.csv ‚Üê OBLIGATOIRE (52 MB)
```

#### 3. Lancer l'application

```bash
streamlit run 01_Accueil.py
```

L'application s'ouvre sur `http://localhost:8501`

---

### D√©ploiement Streamlit Cloud

#### 1. Pr√©paration du repository

```bash
# V√©rifier que les fichiers critiques sont track√©s
git ls-files | grep -E "(\.pkl|hellowork_cleaned_complete\.csv)"

# Si manquants, les ajouter (m√™me si dans .gitignore)
git add -f models/best_model_XGBoost_fixed.pkl
git add -f output/hellowork_cleaned_complete.csv
git add -f output/test_data.pkl

git commit -m "Add critical data files for deployment"
git push origin main
```

#### 2. Configuration Streamlit Cloud

1. Aller sur https://share.streamlit.io/
2. Cliquer "New app"
3. S√©lectionner :
   - Repository : `Paguy-Stream/Projet_machine_learning`
   - Branch : `main`
   - Main file : `01_Accueil.py`
4. Advanced settings :
   - Python version : `3.13`
5. Deploy !

#### 3. Fichiers de configuration

**`.streamlit/config.toml`** :
```toml
[theme]
primaryColor = "#1f77b4"
backgroundColor = "#ffffff"
secondaryBackgroundColor = "#f0f2f6"
textColor = "#262730"
font = "sans serif"

[server]
maxUploadSize = 200
enableCORS = false
enableXsrfProtection = true
```

**`requirements.txt`** :
```txt
streamlit==1.31.0
pandas==2.1.4
numpy==1.26.2
scikit-learn==1.3.2
xgboost==2.0.3
lightgbm==4.1.0
shap==0.44.0
plotly==5.18.0
matplotlib==3.8.2
seaborn==0.13.0
python-dateutil==2.8.2
openpyxl==3.1.2
joblib==1.3.2
beautifulsoup4==4.12.2
requests==2.31.0
pytest==7.4.3
pytest-cov==4.1.0
pytest-mock==3.12.0
```

**Important** : 
- ‚ùå Ne PAS inclure `scipy` (Streamlit Cloud l'installe automatiquement)
- ‚ùå Ne PAS inclure `statsmodels` (incompatibilit√©)

---

### Variables d'environnement

Aucune variable d'environnement requise. Tous les chemins sont dynamiques via `Path(__file__).parent.parent`.

---

## üë®‚Äçüíª Guide de d√©veloppement

### Convention de nommage

#### Fichiers
```
Pages Streamlit    : 01_Accueil.py, 02_Marche.py (PascalCase)
Modules internes   : market_analysis_impl.py (snake_case)
Utilitaires        : config.py, model_utils.py (snake_case)
Tests              : test_model_utils.py (pr√©fixe test_)
```

#### Code Python
```python
# Classes : PascalCase
class ModelUtils:
    pass

# Fonctions : snake_case
def calculate_percentile():
    pass

# Constantes : SCREAMING_SNAKE_CASE
MAX_SALARY = 150000

# Variables : snake_case
user_profile = {}

# Cl√©s Streamlit : {page}_{section}_{type}_{purpose}
key="market_filter_salary"
key="career_skill_python"
key="nav_btn_prediction"
```

---

### Bonnes pratiques Streamlit

#### 1. Cl√©s uniques obligatoires

```python
# ‚úÖ BON
st.selectbox("Ville", options, key="market_filter_city")
st.button("Analyser", key="career_btn_analyze")

# ‚ùå MAUVAIS (cause des erreurs removeChild)
st.selectbox("Ville", options)  # Pas de cl√©
st.button("Analyser")  # Pas de cl√©
```

#### 2. Formulaires

```python
# ‚úÖ BON
with st.form("my_form", clear_on_submit=False):
    city = st.selectbox("Ville", options, key="form_city")
    submit = st.form_submit_button("Soumettre")  # PAS de key ici
    
# ‚ùå MAUVAIS
with st.form("my_form"):
    submit = st.form_submit_button("Soumettre", key="btn_submit")  # Erreur !
```

#### 3. Cache

```python
# Cache donn√©es
@st.cache_data
def load_data():
    return pd.read_csv("data.csv")

# Cache ressources (mod√®les)
@st.cache_resource
def load_model():
    return joblib.load("model.pkl")

# Clear cache
st.cache_data.clear()
```

#### 4. Session state

```python
# Initialisation
if 'prediction_made' not in st.session_state:
    st.session_state.prediction_made = False

# Utilisation
if st.button("Pr√©dire"):
    st.session_state.prediction_made = True
    st.session_state.last_result = result
```

---

### Tests

#### Lancer les tests

```bash
# Tous les tests
pytest

# Avec coverage
pytest --cov=. --cov-report=html

# Test sp√©cifique
pytest tests/test_model_utils.py

# Verbose
pytest -v
```

#### √âcrire un test

```python
import pytest
from utils.model_utils import CalculationUtils

def test_calculate_percentile():
    """Test du calcul de percentile"""
    market_data = np.array([30000, 40000, 50000, 60000, 70000])
    result = CalculationUtils.get_percentile_real(50000, market_data)
    assert 45 <= result <= 55  # Tol√©rance

def test_predict_with_mock(mocker):
    """Test avec mock"""
    mocker.patch('utils.model_utils.ModelUtils.predict', return_value={
        'prediction': 50000,
        'confidence': 0.85
    })
    # ... rest of test
```

---

### Git workflow

```bash
# 1. Cr√©er une branche
git checkout -b feature/nouvelle-fonctionnalite

# 2. D√©velopper + commit fr√©quents
git add .
git commit -m "feat: Add new feature"

# 3. Push
git push origin feature/nouvelle-fonctionnalite

# 4. Cr√©er Pull Request sur GitHub

# 5. Merge dans main
git checkout main
git pull origin main
git merge feature/nouvelle-fonctionnalite
git push origin main

# 6. Delete branch
git branch -d feature/nouvelle-fonctionnalite
```

#### Messages de commit

```bash
# Format : <type>: <description>

feat: Add salary projection feature
fix: Correct percentile calculation
docs: Update README with deployment guide
style: Format code with black
refactor: Reorganize market analysis module
test: Add tests for career module
chore: Update dependencies
```

---

## üîß D√©pannage

### Erreurs courantes

#### 1. `ModuleNotFoundError: No module named 'internal.xxx'`

**Cause** : Module manquant dans `internal/`

**Solution** :
```bash
# Cr√©er un placeholder
cat > internal/xxx.py << EOF
"""Placeholder module"""
import streamlit as st

def render_xxx(*args, **kwargs):
    st.info("Fonctionnalit√© en d√©veloppement")
EOF

git add internal/xxx.py
git commit -m "Add placeholder for xxx module"
git push
```

---

#### 2. `ValueError: Invalid property 'weight' for Font`

**Cause** : Plotly n'accepte pas la propri√©t√© `weight` pour les fonts

**Solution** : Dans `utils/model_utils.py`, ligne ~1040
```python
# ‚ùå AVANT
number={'font': {'size': 32, 'weight': 'bold'}}

# ‚úÖ APR√àS
number={'font': {'size': 32}}  # Supprimer 'weight'
```

---

#### 3. `File not found: /mount/src/.../models/xxx.pkl`

**Cause** : Chemins en dur au lieu de dynamiques

**Solution** : Dans `utils/config.py`
```python
# ‚ùå AVANT
DATA_PATH = Path("data/file.csv")

# ‚úÖ APR√àS
BASE_DIR = Path(__file__).parent.parent
DATA_PATH = BASE_DIR / "output" / "file.csv"
```

---

#### 4. `TypeError: form_submit_button() got an unexpected keyword argument 'key'`

**Cause** : `st.form_submit_button()` ne prend PAS de param√®tre `key`

**Solution** :
```python
# ‚ùå AVANT
st.form_submit_button("Submit", key="btn_submit")

# ‚úÖ APR√àS
st.form_submit_button("Submit")  # Pas de key
```

---

#### 5. `ImportError: cannot import name '_lazywhere' from 'scipy._lib._util'`

**Cause** : Incompatibilit√© statsmodels/scipy

**Solutions** :
1. **Supprimer scipy du requirements.txt** (Streamlit Cloud l'installe automatiquement)
2. **Supprimer `trendline='lowess'`** des graphiques scatter :

```python
# ‚ùå AVANT
fig = px.scatter(data, x='x', y='y', trendline='lowess')

# ‚úÖ APR√àS
fig = px.scatter(data, x='x', y='y')  # Pas de trendline
```

---

#### 6. Erreur `removeChild` dans la console

**Cause** : Widgets Streamlit sans cl√©s uniques

**Solution** : Ajouter des cl√©s √† TOUS les widgets
```python
# ‚ùå AVANT
st.button("Analyser")
st.selectbox("Ville", options)

# ‚úÖ APR√àS
st.button("Analyser", key="page_btn_analyze")
st.selectbox("Ville", options, key="page_select_city")
```

**Pattern de nommage** : `{page}_{section}_{type}_{purpose}`

---

### Debug sur Streamlit Cloud

#### Acc√©der aux logs

1. Aller sur l'app Streamlit Cloud
2. Cliquer "Manage app" (coin inf√©rieur droit)
3. Onglet "Logs"
4. Chercher les erreurs (stack traces en rouge)

#### Ajouter du debug

```python
# Afficher les chemins
st.sidebar.write(f"BASE_DIR: {Config.BASE_DIR}")
st.sidebar.write(f"DATA exists: {Config.DATA_PATH.exists()}")

# Afficher les variables
st.write(f"Profile: {profile_data}")
st.write(f"Prediction: {result}")
```

#### Cr√©er une page debug d√©di√©e

Voir `pages/99_Debug.py` pour un exemple complet de page de debug avec :
- Affichage des chemins
- V√©rification des fichiers
- Test des imports
- Recherche r√©cursive de fichiers

---

## üó∫Ô∏è Feuille de route

### Version 2.2 (Court terme - 1-2 mois)

- [ ] **Multi-sources de donn√©es** : Int√©grer LinkedIn, Indeed, Glassdoor
- [ ] **Am√©lioration mod√®le** : R¬≤ > 0.40 avec ensemble methods
- [ ] **Dark mode** : Th√®me sombre pour l'UI
- [ ] **Export am√©lior√©** : PDF avec graphiques, rapport complet
- [ ] **Comparateur de profils** : Comparer 2+ profils c√¥te √† c√¥te
- [ ] **Alertes salariales** : Notifications si salaire change
- [ ] **Plus de visualisations** : Heatmaps g√©ographiques, network graphs

### Version 3.0 (Moyen terme - 3-6 mois)

- [ ] **API REST** : Endpoint `/predict` pour int√©grations externes
- [ ] **Recommandations formations** : Coursera, Udemy, OpenClassrooms
- [ ] **D√©ploiement cloud** : AWS Lambda ou Google Cloud Run
- [ ] **Authentification** : Comptes utilisateurs avec historique
- [ ] **Tableau de bord personnel** : Suivi √©volution carri√®re
- [ ] **Int√©gration calendrier** : Suivi objectifs professionnels
- [ ] **Notifications** : Email/SMS pour opportunit√©s

### Version 4.0 (Long terme - 6-12 mois)

- [ ] **NLP avanc√©** : BERT/GPT pour analyse descriptions de poste
- [ ] **Pr√©diction √©volution march√©** : Tendances sur 1-2 ans
- [ ] **Plateforme collaborative** : Communaut√©, forum, partage d'exp√©riences
- [ ] **Matching offres/candidats** : Algorithme de recommandation
- [ ] **Mobile app** : iOS et Android natives

---

## üìû Support et contribution

### Contribuer

1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/AmazingFeature`)
3. Commit (`git commit -m 'Add some AmazingFeature'`)
4. Push (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Signaler un bug

Ouvrir une issue sur GitHub avec :
- Description du bug
- √âtapes pour reproduire
- Comportement attendu vs r√©el
- Environnement (OS, Python version, navigateur)
- Logs/screenshots si possible

### Contact

- **GitHub** : https://github.com/Paguy-Stream/Projet_machine_learning
- **Email** : [Votre email]
- **LinkedIn** : [Votre LinkedIn]

---

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

---

## üôè Remerciements

- **HelloWork** : Pour les donn√©es d'offres d'emploi
- **Streamlit** : Pour le framework web
- **Anthropic Claude** : Pour l'assistance au d√©veloppement
- **Communaut√© Data** : Pour les retours et suggestions

---

**Version du guide** : 2.1  
**Derni√®re mise √† jour** : F√©vrier 2026  
**Auteur** : Emmanuel / Data Team

---

## üìö Annexes

### A. Glossaire

| Terme | D√©finition |
|-------|------------|
| **MAE** | Mean Absolute Error - Erreur moyenne absolue |
| **R¬≤** | Coefficient de d√©termination - Qualit√© de l'ajustement |
| **RMSE** | Root Mean Square Error - Erreur quadratique moyenne |
| **SHAP** | SHapley Additive exPlanations - Explicabilit√© ML |
| **XGBoost** | eXtreme Gradient Boosting - Algorithme ML |
| **Percentile** | Position relative dans une distribution (0-100) |
| **Multiplicateur** | Coefficient d'ajustement salarial (ville/secteur) |

### B. R√©f√©rences utiles

- [Streamlit Documentation](https://docs.streamlit.io/)
- [Plotly Documentation](https://plotly.com/python/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

### C. Commandes utiles

```bash
# D√©veloppement
streamlit run 01_Accueil.py --server.port 8502  # Port custom
streamlit run 01_Accueil.py --server.headless true  # Sans browser

# Tests
pytest --maxfail=1  # Stop au premier √©chec
pytest -k "test_model"  # Tests contenant "test_model"
pytest --pdb  # Debugger interactif

# Git
git log --oneline --graph --all  # Historique graphique
git diff HEAD~1  # Diff avec commit pr√©c√©dent
git stash  # Sauvegarder changements temporairement

# Python
python -m pip list --outdated  # Packages √† mettre √† jour
python -m pip install -U <package>  # Upgrade package
```

---

**Fin du guide** üéâ

Ce document sera mis √† jour au fur et √† mesure de l'√©volution du projet.