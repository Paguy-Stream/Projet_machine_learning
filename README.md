# ğŸ’¼ PrÃ©dicteur de Salaires - MÃ©tiers de la Data

[![Python](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.31-red.svg)](https://streamlit.io/)
[![XGBoost](https://img.shields.io/badge/XGBoost-2.0-green.svg)](https://xgboost.readthedocs.io/)
[![Tests](https://img.shields.io/badge/Tests-99%20passing-brightgreen.svg)]()
[![Coverage](https://img.shields.io/badge/Coverage-70%25-yellow.svg)]()
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

> Ce projet analyse 5 868 offres dâ€™emploi Data collectÃ©es sur HelloWork en janvier 2026, afin dâ€™estimer le salaire annuel brut Ã  partir de 29 variables explicatives. Le modÃ¨le XGBoost retenu atteint un RÂ² de 0.337 et une erreur absolue moyenne de 5 163 â‚¬. 

AccÃ©der Ã  lâ€™application en ligne:
ğŸ”— Application Streamlit : https://projetmachinelearning.streamlit.app/

![Page d'accueil](images/gift_acceuil.gif)

---

## ğŸ“‹ Table des matiÃ¨res

- [Description du projet](#-description-du-projet)
- [Contexte et problÃ©matique](#-contexte-et-problÃ©matique)
- [DÃ©marche et objectifs](#-dÃ©marche-et-objectifs)
- [MÃ©thodologie](#-mÃ©thodologie)
- [RÃ©sultats du Machine Learning](#-rÃ©sultats-du-machine-learning)
- [Utilisation de l'application](#-utilisation-de-lapplication)
- [Installation](#-installation)
- [Structure du projet](#-structure-du-projet)
- [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
- [Axes d'amÃ©lioration](#-axes-damÃ©lioration)
- [Auteurs](#-auteurs)
- [License](#-license)

---

##  Description du projet

Ce projet vise Ã  **prÃ©dire les salaires** des mÃ©tiers de la Data en France en exploitant des donnÃ©es  d'offres d'emploi non structurÃ©es. Ã€ travers une application web interactive dÃ©veloppÃ©e avec **Streamlit**, il offre trois fonctionnalitÃ©s principales :

1. ** PrÃ©diction de salaire** - Estimation salariale pour un profil donnÃ©,
2. ** Analyse de marchÃ©** - Vue d'ensemble des tendances observÃ©es dans les donnÃ©es,
3. ** Conseil carriÃ¨re** - simulation de lâ€™impact de certains choix professionnels.

Les rÃ©sultats reflÃ¨tent les tendances prÃ©sentes dans le dataset. Le modÃ¨le a un RÂ² de 0.337 et une erreur absolue moyenne de 5 163 â‚¬. Ces limites sont affichÃ©es pour contextualiser les estimations proposÃ©es.

> Ce modÃ¨le ne prÃ©tend pas dÃ©terminer la "valeur" dâ€™un candidat, mais reflÃ¨te les tendances observÃ©es dans un corpus spÃ©cifique dâ€™offres dâ€™emploi. Il ne doit pas Ãªtre utilisÃ© comme unique rÃ©fÃ©rence pour des dÃ©cisions de recrutement ou de nÃ©gociation salariale.

### Question centrale de recherche

> **Quels facteurs observables dans les offres dâ€™emploi expliquent la variance des salaires dans le domaine Data en France ?**

---

##  Contexte et problÃ©matique

Le marchÃ© de l'emploi dans la Data se distingue par une **Ã©volution rapide des technologies** et une **transformation profonde des mÃ©tiers**. Aujourd'hui, un profil "Data" ne se dÃ©finit plus uniquement par son intitulÃ© de poste ou son parcours acadÃ©mique, mais par une **combinaison prÃ©cise de compÃ©tences techniques**, allant de la maÃ®trise de langages de programmation aux environnements Cloud.

### DÃ©fis identifiÃ©s

Cette complexitÃ© structurelle crÃ©e un marchÃ© de l'emploi trÃ¨s actif oÃ¹ :

-  **Les rÃ©fÃ©rences de rÃ©munÃ©ration fluctuent en permanence**
-  **L'orientation professionnelle devient complexe** pour les futurs diplÃ´mÃ©s
-  **Les informations sont dispersÃ©es** dans des milliers d'annonces hÃ©tÃ©rogÃ¨nes
-  **L'Ã©valuation de sa propre valeur sur le marchÃ©** est particuliÃ¨rement dÃ©licate

### NÃ©cessitÃ© du projet

Dans ce contexte de **forte volatilitÃ©**, il existe une difficultÃ© rÃ©elle Ã  Ã©valuer l'impact concret de chaque critÃ¨re sur le salaire proposÃ©. Il devient donc nÃ©cessaire de **transformer ces donnÃ©es brutes en informations structurÃ©es** afin de comprendre comment les recruteurs valorisent rÃ©ellement :

- Une expertise technique (Python, SQL, Cloud, ML/DL)
- Des facteurs traditionnels (localisation, expÃ©rience, formation)
- Les synergies entre compÃ©tences

---

##  DÃ©marche et objectifs

### Objectifs de l'Ã©tude

Ce travail est structurÃ© autour des axes suivants :

1. ** VÃ©rifier la capacitÃ© de prÃ©diction**
   - Tester si l'extraction de variables techniques permet de faire converger un modÃ¨le vers une estimation salariale cohÃ©rente

2. ** Analyser la hiÃ©rarchie des signaux**
   - Mesurer le poids relatif de l'expertise technique face aux dÃ©terminants gÃ©ographiques traditionnels

3. ** Ã‰tudier les synergies entre compÃ©tences**
   - Identifier les combinaisons crÃ©ant des sauts de valeur non-linÃ©aires

4. ** Cartographier la distribution des opportunitÃ©s**
   - Ã€ partir de donnÃ©es extraites de HelloWork.com

5. ** Fournir des indicateurs concrets**
   - Pour l'orientation et l'Ã©valuation de profil des futurs candidats

### PÃ©rimÃ¨tre de l'Ã©tude

L'analyse porte sur un Ã©chantillon de **5,868 offres d'emploi** collectÃ©es via web scraping.

**MÃ©tiers ciblÃ©s** :
- Data Scientist
- Data Engineer
- Data Analyst
- BI Analyst
- ML Engineer

**Variables explicatives** :
- Stack technique (Python, SQL, R, Cloud, BI tools)
- ExpÃ©rience requise
- Localisation gÃ©ographique
- Secteur d'activitÃ©
- Niveau de formation
- Avantages sociaux

---

##  MÃ©thodologie

### 1. Web Scraping

**Source** : HelloWork.com  
**PÃ©riode** : Janvier 2026  
**Volume** : 5,868 offres d'emploi

```python
# DonnÃ©es collectÃ©es
- Titre du poste
- Description complÃ¨te
- Fourchette salariale
- Localisation
- CompÃ©tences requises
- Avantages sociaux
```

**Outils** : Botright, Requests, Pandas

### 2. Nettoyage et Feature Engineering

**Pipeline de traitement** :
-  Nettoyage des descriptions 
-  Extraction d'expÃ©rience (patterns regex + correction des valeurs extrÃªmes)
-  Parsing de compÃ©tences (12+ technologies dÃ©tectÃ©es)
-  Normalisation des salaires (support kâ‚¬ et â‚¬)
- CrÃ©ation de 101 colonnes au total, dont 29 utilisÃ©es comme features dâ€™entrÃ©e

**Architecture** :
```python
ExperienceExtractor      # Extraction  d'expÃ©rience
CompanyExtractor        # DÃ©tection d'entreprises
LocationExtractor       # GÃ©olocalisation
JobTypeClassifier       # Classification de postes
DescriptionCleaner      # Nettoyage de texte
```

### 3. ModÃ©lisation Machine Learning

**Approche** :
- Split stratifiÃ© (80% train / 20% test)
- Cross-validation 5-fold
- GridSearchCV pour l'optimisation
- PrÃ©vention stricte de l'overfitting

**ModÃ¨les testÃ©s** :
1. Ridge / Lasso / ElasticNet (rÃ©gularisation L1/L2)
2. Random Forest (min_samples_leaf=20)
3. Gradient Boosting (subsample=0.8)
4. **XGBoost**  (modÃ¨le retenu)
5. LightGBM (feature_fraction=0.7)

---

##  RÃ©sultats du Machine Learning

### ModÃ¨le retenu : XGBoost

**Performances** :

| MÃ©trique | Train | Test | Cross-Validation |
|----------|-------|------|------------------|
| **RÂ²** | 0.451 | **0.337** | 0.315 (Â±0.028) |
| **MAE** | 4,328â‚¬ | **5,163â‚¬** | 5,421â‚¬ (Â±315â‚¬) |
| **RMSE** | 6,547â‚¬ | **7,854â‚¬** | 8,012â‚¬ (Â±421â‚¬) |

**Taux d'erreur moyen** : ~11% du salaire prÃ©dit

### PrÃ©cision par marge d'erreur

| Marge | % de prÃ©dictions correctes |
|-------|---------------------------|
| **Â±5%** | 23.4% |
| **Â±10%** | 47.8% |
| **Â±15%** | 68.2% |
| **Â±20%** | 82.5% |

### Features les plus importantes

**Top 10 variables explicatives** :

1. **ExpÃ©rience** (annÃ©es) - 18.2%
2. **Score technique global** - 14.7%
3. **Nombre de compÃ©tences** - 12.3%
4. **Localisation** (Paris vs Province) - 9.8%
5. **Secteur d'activitÃ©** - 8.4%
6. **CompÃ©tences Cloud** (AWS/Azure/GCP) - 7.2%
7. **SÃ©nioritÃ©** (Junior/Mid/Senior) - 6.9%
8. **Machine Learning / Deep Learning** - 5.8%
9. **Type de contrat** (CDI/CDD/Freelance) - 4.6%
10. **Formation** (Bac+3/5/8) - 4.1%

### Diagnostic d'overfitting

**Î”RÂ² (Train - Test)** : 0.114 â†’ âœ… **Overfitting maÃ®trisÃ©**

**StratÃ©gies de rÃ©gularisation appliquÃ©es** :
- `max_depth=3` (limitation de profondeur)
- `min_child_weight=10` (samples minimum par feuille)
- `reg_alpha=5.0` (rÃ©gularisation L1)
- `reg_lambda=10.0` (rÃ©gularisation L2)
- `subsample=0.7` (bagging d'Ã©chantillons)
- `colsample_bytree=0.7` (bagging de features)

---

##  Utilisation de l'application

### Page d'accueil

> _Â« SynthÃ¨se des tendances observÃ©es dans les 5 868 offres analysÃ©es, avec mÃ©triques du modÃ¨le et navigation vers les fonctionnalitÃ©s principales. Â»_

![Accueil](images/gift_acceuil.gif)

**FonctionnalitÃ©s** : 

- ğŸ“Š Vue d'ensemble du marchÃ© (4,253 postes Data analysÃ©s)
- ğŸ’° Salaire mÃ©dian par type de poste
- ğŸ”¥ Top compÃ©tences les plus demandÃ©es
- ğŸ“ˆ RÃ©partition gÃ©ographique des offres

---

### 1. ğŸ”® Module PrÃ©diction

> _Â«Estimation salariale basÃ©e sur le modÃ¨le XGBoost, accompagnÃ©e dâ€™une fourchette rÃ©aliste (Â±7 417 â‚¬) et dâ€™un positionnement par rapport au marchÃ© rÃ©el.Â»_

![PrÃ©diction](images/gift_pred.gif)

**FonctionnalitÃ©s** :

- **Formulaire de profil** : Type de poste, expÃ©rience, compÃ©tences, localisation
- **PrÃ©diction instantanÃ©e** : Salaire estimÃ© avec intervalle de confiance (Â±MAE)
- **ExplicabilitÃ© SHAP** : Contribution de chaque variable Ã  la prÃ©diction
- **Positionnement marchÃ©** : Votre salaire vs la distribution du marchÃ©

![PrÃ©diction dÃ©taillÃ©e](images/gift_pred_02.gif)

**Comparaisons avancÃ©es** :
-  **Par secteur** : Tech, Banque, ESN, Assurance, etc.
-  **Par ville** : Paris, Lyon, Toulouse, Bordeaux, etc.
- â± **Projection carriÃ¨re** : Ã‰volution salariale sur 10 ans
-  **Impact des compÃ©tences** : Gain salarial par skill (+Python, +AWS, +ML/DL)

---

### 2. Module MarchÃ©

 > _Â«Exploration interactive des donnÃ©es : filtres par poste, ville, secteur ou compÃ©tences, avec visualisations des distributions et impacts salariaux observÃ©s.Â»_

![MarchÃ©](images/gift_marche.gif)

**Onglets d'analyse** :

** Vue d'ensemble**
- Distribution des salaires (histogramme + boxplot)
- Salaire mÃ©dian par type de contrat
- Ã‰volution salaire vs expÃ©rience

** Jobs & Secteurs**
- Top 10 mÃ©tiers Data les mieux payÃ©s
- Salaires par secteur d'activitÃ©
- Multiplicateurs sectoriels (Tech: +8%, Banque: +12%)

** GÃ©ographie**
- Top 10 villes par salaire moyen
- Heatmap France (salaires moyens par rÃ©gion)
- Multiplicateurs gÃ©ographiques (Paris: +15%)

** CompÃ©tences**
- FrÃ©quence des compÃ©tences (Python: 68%, SQL: 72%)
- Impact salarial par compÃ©tence (+Python: +3.2kâ‚¬, +AWS: +5.8kâ‚¬)

** Combinaisons**
- Stacks techniques populaires (Python+SQL+Cloud, etc.)
- ROI des combinaisons (gains salariaux)

---

### 3. Module CarriÃ¨re

> _Â« Simulation de lâ€™impact de dÃ©cisions concrÃ¨tes (ex. : localisation, acquisition de compÃ©tences) et projection de trajectoire fondÃ©e sur la distribution rÃ©elle des salaires par expÃ©rience.. Â»_

![CarriÃ¨re](images/gift_carriere.gif)

**FonctionnalitÃ©s** :

**ğŸ“Š Diagnostic de positionnement**
- Score d'employabilitÃ© (0-100)
- Positionnement vs marchÃ© (percentile)
- Gain de compÃ©tence optimal

**ğŸ—ºï¸ Roadmap de compÃ©tences**
- Identification des compÃ©tences manquantes
- Calcul de l'impact salarial (+Python: +3.2kâ‚¬)
- Matrice Effort/Impact pour prioriser

**ğŸ”„ Transitions de carriÃ¨re**
- Top 3 transitions possibles (ex: Data Analyst â†’ Data Scientist)
- CompÃ©tences requises pour chaque transition
- Gain salarial estimÃ© (+12kâ‚¬ en moyenne)

**ğŸ“ˆ Projection salariale**
- Ã‰volution sur 10 ans (3 scÃ©narios)
- Graphique interactif

---

##  Installation

### PrÃ©requis

- **Python** 3.13+
- **pip** (gestionnaire de paquets)

### Installation rapide

```bash
# 1. Cloner le repository
git clone https://github.com/votre-username/predicteur-salaires-data.git
cd predicteur-salaires-data

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv

# Sur Windows
venv\Scripts\activate

# Sur macOS/Linux
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Lancer l'application
streamlit run 01_Accueil.py
```

L'application sera accessible Ã  l'adresse : **http://localhost:8501**

---

##  Structure du projet

```
Projet_Salaires_Data/
â”‚
â”œâ”€â”€ 01_Accueil.py                    #  Page d'accueil Streamlit
â”‚
â”œâ”€â”€ pages/                            #  Pages de l'application
â”‚   â”œâ”€â”€ 01_Prediction.py             #  Module prÃ©diction
â”‚   â”œâ”€â”€ 02_Marche.py                 #  Module marchÃ©
â”‚   â””â”€â”€ 03_Carriere.py               #  Module carriÃ¨re
â”‚
â”œâ”€â”€ internal/                         #   ImplÃ©mentations internes
â”‚   â”œâ”€â”€ prediction_display_impl.py
â”‚   â”œâ”€â”€ prediction_comparisons_impl.py
â”‚   â”œâ”€â”€ prediction_actions_impl.py
â”‚   â”œâ”€â”€ career_*.py
â”‚   â””â”€â”€ market_*.py
â”‚
â”œâ”€â”€ utils/                            #  Utilitaires
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â””â”€â”€ feature_engineer.py
â”‚
â”œâ”€â”€ models/                           #  ModÃ¨les ML
â”‚   â”œâ”€â”€ best_model_XGBoost.pkl
â”‚   â””â”€â”€ modeling_report_v7.json
â”‚
â”œâ”€â”€ scripts/                          #  Scripts de traitement
â”‚   â”œâ”€â”€ data_cleaning_refactored_part1.py
â”‚   â”œâ”€â”€ data_cleaning_refactored_part2.py
â”‚   â””â”€â”€ modeling_refactored.py
â”‚
â”œâ”€â”€ tests/                            #  Tests (99 tests)
â”‚   â”œâ”€â”€ test_model_utils.py
â”‚   â”œâ”€â”€ test_modeling_refactored.py
â”‚   â””â”€â”€ test_simplified.py
â”‚
â”œâ”€â”€ images/                           #   GIFs de dÃ©monstration
â”‚   â”œâ”€â”€ gift_acceuil.gif
â”‚   â”œâ”€â”€ gift_pred.gif
â”‚   â”œâ”€â”€ gift_marche.gif
â”‚   â””â”€â”€ gift_carriere.gif
â”‚
â””â”€â”€ requirements.txt                  #  DÃ©pendances
```

---

##  Technologies utilisÃ©es

### Frontend
- **Streamlit** 1.31 - Interface web
- **Plotly** 5.18 - Graphiques interactifs
- **Matplotlib/Seaborn** - Visualisations

### Machine Learning
- **XGBoost** 2.0 - ModÃ¨le principal
- **LightGBM** 4.1 - ModÃ¨le alternatif
- **scikit-learn** 1.3 - Preprocessing
- **SHAP** 0.44 - ExplicabilitÃ©

### Data Processing
- **Pandas** 2.1 - Manipulation de donnÃ©es
- **NumPy** 1.26 - Calculs numÃ©riques

### Testing
- **pytest** 7.4 - Tests unitaires
- **pytest-cov** 4.1 - Couverture

---

##  Axes d'amÃ©lioration

### Court terme
- [ ] Ajout de sources de donnÃ©es (Indeed, LinkedIn)
- [ ] AmÃ©lioration du modÃ¨le (RÂ² >0.40)
- [ ] Mode sombre et export PDF

### Moyen terme
- [ ] API REST pour prÃ©dictions
- [ ] SystÃ¨me de recommandations de formations
- [ ] DÃ©ploiement cloud (AWS/Streamlit Cloud)

### Long terme
- [ ] NLP avancÃ© (BERT, GPT)
- [ ] PrÃ©diction d'Ã©volution du marchÃ©
- [ ] Plateforme collaborative

---

## ğŸ‘¥ Auteurs

**Emmanuel Paguiel**
- ğŸ“ Etudiant en Economie de l'entreprise


---

## ğŸ™ Remerciements

- **HelloWork.com** pour les donnÃ©es
- **CommunautÃ© Streamlit**
- **Anthropic Claude** pour l'assistance

---

## ğŸ“„ License

MIT License - Copyright (c) 2026 Emmanuel

---
