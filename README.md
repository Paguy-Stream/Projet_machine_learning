# ğŸ’¼ PrÃ©dicteur de Salaires - MÃ©tiers de la Data

[![Python](https://img.shields.io/badge/Python-3.13-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.31-red.svg)](https://streamlit.io/)
[![XGBoost](https://img.shields.io/badge/XGBoost-2.0-green.svg)](https://xgboost.readthedocs.io/)
[![Tests](https://img.shields.io/badge/Tests-99%20passing-brightgreen.svg)]()
[![Coverage](https://img.shields.io/badge/Coverage-70%25-yellow.svg)]()
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

> **Application Streamlit interactive** pour prÃ©dire et analyser les salaires des mÃ©tiers de la Data en France, basÃ©e sur un modÃ¨le XGBoost entraÃ®nÃ© sur 5,868 offres d'emploi rÃ©elles.

![Page d'accueil](images/gift_acceuil.gif)

---

## ğŸ“‹ Table des matiÃ¨res

- [Description du projet](#-description-du-projet)
- [Contexte et problÃ©matique](#-contexte-et-problÃ©matique)
- [DÃ©marche et objectifs](#-dÃ©marche-et-objectifs)
- [MÃ©thodologie](#-mÃ©thodologie)
- [RÃ©sultats du Machine Learning](#-rÃ©sultats-du-machine-learning)
- [Utilisation de l'application](#-utilisation-de-lapplication)
- [Installation](#-installation)
- [Structure du projet](#-structure-du-projet)
- [Technologies utilisÃ©es](#-technologies-utilisÃ©es)
- [Axes d'amÃ©lioration](#-axes-damÃ©lioration)
- [Auteurs](#-auteurs)
- [License](#-license)

---

## ğŸ¯ Description du projet

Ce projet vise Ã  **prÃ©dire les salaires** des mÃ©tiers de la Data en France en exploitant des donnÃ©es  d'offres d'emploi non structurÃ©es. Ã€ travers une application web interactive dÃ©veloppÃ©e avec **Streamlit**, il offre trois fonctionnalitÃ©s principales :

1. **ğŸ”® PrÃ©diction de salaire** - Estimation personnalisÃ©e basÃ©e sur votre profil
2. **ğŸ“Š Analyse de marchÃ©** - Vue d'ensemble du marchÃ© de l'emploi Data
3. **ğŸ“ Conseil carriÃ¨re** - Roadmap de compÃ©tences et transitions professionnelles

### Question centrale de recherche

> **Â« Comment construire un modÃ¨le de rÃ©gression capable de prÃ©dire la fourchette salariale Ã  partir de features hÃ©tÃ©rogÃ¨nes (texte, catÃ©gories, gÃ©ographie) extraites d'annonces non structurÃ©es ? Â»**

---

## ğŸŒ Contexte et problÃ©matique

Le marchÃ© de l'emploi dans la Data se distingue par une **Ã©volution extrÃªmement rapide des technologies** et une **transformation profonde des mÃ©tiers**. Aujourd'hui, un profil "Data" ne se dÃ©finit plus uniquement par son intitulÃ© de poste ou son parcours acadÃ©mique, mais par une **combinaison prÃ©cise de compÃ©tences techniques**, allant de la maÃ®trise de langages de programmation aux environnements Cloud.

### DÃ©fis identifiÃ©s

Cette complexitÃ© structurelle crÃ©e un marchÃ© de l'emploi trÃ¨s actif oÃ¹ :

- âš¡ **Les rÃ©fÃ©rences de rÃ©munÃ©ration fluctuent en permanence**
- ğŸ¯ **L'orientation professionnelle devient complexe** pour les futurs diplÃ´mÃ©s
- ğŸ“Š **Les informations sont dispersÃ©es** dans des milliers d'annonces hÃ©tÃ©rogÃ¨nes
- ğŸ” **L'Ã©valuation de sa propre valeur sur le marchÃ©** est particuliÃ¨rement dÃ©licate

### NÃ©cessitÃ© du projet

Dans ce contexte de **forte volatilitÃ©**, il existe une difficultÃ© rÃ©elle Ã  Ã©valuer l'impact concret de chaque critÃ¨re sur le salaire proposÃ©. Il devient donc nÃ©cessaire de **transformer ces donnÃ©es brutes en informations structurÃ©es** afin de comprendre comment les recruteurs valorisent rÃ©ellement :

- Une expertise technique (Python, SQL, Cloud, ML/DL)
- Des facteurs traditionnels (localisation, expÃ©rience, formation)
- Les synergies entre compÃ©tences

---

## ğŸ¯ DÃ©marche et objectifs

### Objectifs de l'Ã©tude

Ce travail est structurÃ© autour des axes suivants :

1. **âœ… VÃ©rifier la capacitÃ© de prÃ©diction**
   - Tester si l'extraction de variables techniques permet de faire converger un modÃ¨le vers une estimation salariale cohÃ©rente

2. **ğŸ“Š Analyser la hiÃ©rarchie des signaux**
   - Mesurer le poids relatif de l'expertise technique face aux dÃ©terminants gÃ©ographiques traditionnels

3. **ğŸ”— Ã‰tudier les synergies entre compÃ©tences**
   - Identifier les combinaisons crÃ©ant des sauts de valeur non-linÃ©aires

4. **ğŸ—ºï¸ Cartographier la distribution des opportunitÃ©s**
   - Ã€ partir de donnÃ©es extraites de HelloWork.com

5. **ğŸ“ Fournir des indicateurs concrets**
   - Pour l'orientation et l'Ã©valuation de profil des futurs candidats

### PÃ©rimÃ¨tre de l'Ã©tude

L'analyse porte sur un Ã©chantillon de **5,868 offres d'emploi** collectÃ©es via web scraping.

**MÃ©tiers ciblÃ©s** :
- Data Scientist
- Data Engineer
- Data Analyst
- BI Analyst
- ML Engineer

**Variables explicatives** :
- Stack technique (Python, SQL, R, Cloud, BI tools)
- ExpÃ©rience requise
- Localisation gÃ©ographique
- Secteur d'activitÃ©
- Niveau de formation
- Avantages sociaux

---

## ğŸ”¬ MÃ©thodologie

### 1. Web Scraping

**Source** : HelloWork.com  
**PÃ©riode** : Janvier 2026  
**Volume** : 5,868 offres d'emploi

```python
# DonnÃ©es collectÃ©es
- Titre du poste
- Description complÃ¨te
- Fourchette salariale
- Localisation
- CompÃ©tences requises
- Avantages sociaux
```

**Outils** : Botright, Requests, Pandas

### 2. Nettoyage et Feature Engineering

**Pipeline de traitement** :
- âœ… Nettoyage des descriptions (suppression de headers/footers)
- âœ… Extraction d'expÃ©rience (patterns regex + correction des valeurs extrÃªmes)
- âœ… Parsing de compÃ©tences (12+ technologies dÃ©tectÃ©es)
- âœ… Normalisation des salaires (support kâ‚¬ et â‚¬)
- âœ… CrÃ©ation de 45+ features dÃ©rivÃ©es

**Architecture** :
```python
ExperienceExtractor      # Extraction  d'expÃ©rience
CompanyExtractor        # DÃ©tection d'entreprises
LocationExtractor       # GÃ©olocalisation
JobTypeClassifier       # Classification de postes
DescriptionCleaner      # Nettoyage de texte
```

### 3. ModÃ©lisation Machine Learning

**Approche** :
- Split stratifiÃ© (80% train / 20% test)
- Cross-validation 5-fold
- GridSearchCV pour l'optimisation
- PrÃ©vention stricte de l'overfitting

**ModÃ¨les testÃ©s** :
1. Ridge / Lasso / ElasticNet (rÃ©gularisation L1/L2)
2. Random Forest (min_samples_leaf=20)
3. Gradient Boosting (subsample=0.8)
4. **XGBoost** â­ (modÃ¨le retenu)
5. LightGBM (feature_fraction=0.7)

---

## ğŸ† RÃ©sultats du Machine Learning

### ModÃ¨le retenu : XGBoost

**Performances** :

| MÃ©trique | Train | Test | Cross-Validation |
|----------|-------|------|------------------|
| **RÂ²** | 0.451 | **0.337** | 0.315 (Â±0.028) |
| **MAE** | 4,328â‚¬ | **5,163â‚¬** | 5,421â‚¬ (Â±315â‚¬) |
| **RMSE** | 6,547â‚¬ | **7,854â‚¬** | 8,012â‚¬ (Â±421â‚¬) |

**Taux d'erreur moyen** : ~11% du salaire prÃ©dit

### PrÃ©cision par marge d'erreur

| Marge | % de prÃ©dictions correctes |
|-------|---------------------------|
| **Â±5%** | 23.4% |
| **Â±10%** | 47.8% |
| **Â±15%** | 68.2% |
| **Â±20%** | 82.5% |

### Features les plus importantes

**Top 10 variables explicatives** :

1. **ExpÃ©rience** (annÃ©es) - 18.2%
2. **Score technique global** - 14.7%
3. **Nombre de compÃ©tences** - 12.3%
4. **Localisation** (Paris vs Province) - 9.8%
5. **Secteur d'activitÃ©** - 8.4%
6. **CompÃ©tences Cloud** (AWS/Azure/GCP) - 7.2%
7. **SÃ©nioritÃ©** (Junior/Mid/Senior) - 6.9%
8. **Machine Learning / Deep Learning** - 5.8%
9. **Type de contrat** (CDI/CDD/Freelance) - 4.6%
10. **Formation** (Bac+3/5/8) - 4.1%

### Diagnostic d'overfitting

**Î”RÂ² (Train - Test)** : 0.114 â†’ âœ… **Overfitting maÃ®trisÃ©**

**StratÃ©gies de rÃ©gularisation appliquÃ©es** :
- `max_depth=3` (limitation de profondeur)
- `min_child_weight=10` (samples minimum par feuille)
- `reg_alpha=5.0` (rÃ©gularisation L1)
- `reg_lambda=10.0` (rÃ©gularisation L2)
- `subsample=0.7` (bagging d'Ã©chantillons)
- `colsample_bytree=0.7` (bagging de features)

---

## ğŸ“± Utilisation de l'application

### Page d'accueil

![Accueil](images/gift_acceuil.gif)

**FonctionnalitÃ©s** :
- ğŸ“Š Vue d'ensemble du marchÃ© (4,253 postes Data analysÃ©s)
- ğŸ’° Salaire mÃ©dian par type de poste
- ğŸ”¥ Top compÃ©tences les plus demandÃ©es
- ğŸ“ˆ RÃ©partition gÃ©ographique des offres

---

### 1. ğŸ”® Module PrÃ©diction

![PrÃ©diction](images/gift_pred.gif)

**FonctionnalitÃ©s** :
- **Formulaire de profil** : Type de poste, expÃ©rience, compÃ©tences, localisation
- **PrÃ©diction instantanÃ©e** : Salaire estimÃ© avec intervalle de confiance (Â±MAE)
- **ExplicabilitÃ© SHAP** : Contribution de chaque variable Ã  la prÃ©diction
- **Positionnement marchÃ©** : Votre salaire vs la distribution du marchÃ©

![PrÃ©diction dÃ©taillÃ©e](images/gift_pred_02.gif)

**Comparaisons avancÃ©es** :
- ğŸ“Š **Par secteur** : Tech, Banque, ESN, Assurance, etc.
- ğŸŒ **Par ville** : Paris, Lyon, Toulouse, Bordeaux, etc.
- â±ï¸ **Projection carriÃ¨re** : Ã‰volution salariale sur 10 ans
- ğŸ”§ **Impact des compÃ©tences** : Gain salarial par skill (+Python, +AWS, +ML/DL)

---

### 2. ğŸ“Š Module MarchÃ©

![MarchÃ©](images/gift_marche.gif)

**Onglets d'analyse** :

**ğŸ“ˆ Vue d'ensemble**
- Distribution des salaires (histogramme + boxplot)
- Salaire mÃ©dian par type de contrat
- Ã‰volution salaire vs expÃ©rience

**ğŸ’¼ Jobs & Secteurs**
- Top 10 mÃ©tiers Data les mieux payÃ©s
- Salaires par secteur d'activitÃ©
- Multiplicateurs sectoriels (Tech: +8%, Banque: +12%)

**ğŸŒ GÃ©ographie**
- Top 10 villes par salaire moyen
- Heatmap France (salaires moyens par rÃ©gion)
- Multiplicateurs gÃ©ographiques (Paris: +15%)

**ğŸ”§ CompÃ©tences**
- FrÃ©quence des compÃ©tences (Python: 68%, SQL: 72%)
- Impact salarial par compÃ©tence (+Python: +3.2kâ‚¬, +AWS: +5.8kâ‚¬)

**ğŸ¯ Combinaisons**
- Stacks techniques populaires (Python+SQL+Cloud, etc.)
- ROI des combinaisons (gains salariaux)

---

### 3. ğŸ“ Module CarriÃ¨re

![CarriÃ¨re](images/gift_carriere.gif)

**FonctionnalitÃ©s** :

**ğŸ“Š Diagnostic de positionnement**
- Score d'employabilitÃ© (0-100)
- Positionnement vs marchÃ© (percentile)
- Gain de compÃ©tence optimal

**ğŸ—ºï¸ Roadmap de compÃ©tences**
- Identification des compÃ©tences manquantes
- Calcul de l'impact salarial (+Python: +3.2kâ‚¬)
- Matrice Effort/Impact pour prioriser

**ğŸ”„ Transitions de carriÃ¨re**
- Top 3 transitions possibles (ex: Data Analyst â†’ Data Scientist)
- CompÃ©tences requises pour chaque transition
- Gain salarial estimÃ© (+12kâ‚¬ en moyenne)

**ğŸ“ˆ Projection salariale**
- Ã‰volution sur 10 ans (3 scÃ©narios)
- Graphique interactif

---

## ğŸš€ Installation

### PrÃ©requis

- **Python** 3.13+
- **pip** (gestionnaire de paquets)

### Installation rapide

```bash
# 1. Cloner le repository
git clone https://github.com/votre-username/predicteur-salaires-data.git
cd predicteur-salaires-data

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv venv

# Sur Windows
venv\Scripts\activate

# Sur macOS/Linux
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Lancer l'application
streamlit run 01_Accueil.py
```

L'application sera accessible Ã  l'adresse : **http://localhost:8501**

---

## ğŸ“ Structure du projet

```
Projet_Salaires_Data/
â”‚
â”œâ”€â”€ 01_Accueil.py                    # ğŸ  Page d'accueil Streamlit
â”‚
â”œâ”€â”€ pages/                            # ğŸ“„ Pages de l'application
â”‚   â”œâ”€â”€ 01_Prediction.py             # ğŸ”® Module prÃ©diction
â”‚   â”œâ”€â”€ 02_Marche.py                 # ğŸ“Š Module marchÃ©
â”‚   â””â”€â”€ 03_Carriere.py               # ğŸ“ Module carriÃ¨re
â”‚
â”œâ”€â”€ internal/                         # âš™ï¸  ImplÃ©mentations internes
â”‚   â”œâ”€â”€ prediction_display_impl.py
â”‚   â”œâ”€â”€ prediction_comparisons_impl.py
â”‚   â”œâ”€â”€ prediction_actions_impl.py
â”‚   â”œâ”€â”€ career_*.py
â”‚   â””â”€â”€ market_*.py
â”‚
â”œâ”€â”€ utils/                            # ğŸ”§ Utilitaires
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ model_utils.py
â”‚   â””â”€â”€ feature_engineer.py
â”‚
â”œâ”€â”€ models/                           # ğŸ¤– ModÃ¨les ML
â”‚   â”œâ”€â”€ best_model_XGBoost.pkl
â”‚   â””â”€â”€ modeling_report_v7.json
â”‚
â”œâ”€â”€ scripts/                          # ğŸ“œ Scripts de traitement
â”‚   â”œâ”€â”€ data_cleaning_refactored_part1.py
â”‚   â”œâ”€â”€ data_cleaning_refactored_part2.py
â”‚   â””â”€â”€ modeling_refactored.py
â”‚
â”œâ”€â”€ tests/                            # ğŸ§ª Tests (99 tests)
â”‚   â”œâ”€â”€ test_model_utils.py
â”‚   â”œâ”€â”€ test_modeling_refactored.py
â”‚   â””â”€â”€ test_simplified.py
â”‚
â”œâ”€â”€ images/                           # ğŸ–¼ï¸  GIFs de dÃ©monstration
â”‚   â”œâ”€â”€ gift_acceuil.gif
â”‚   â”œâ”€â”€ gift_pred.gif
â”‚   â”œâ”€â”€ gift_marche.gif
â”‚   â””â”€â”€ gift_carriere.gif
â”‚
â””â”€â”€ requirements.txt                  # ğŸ“¦ DÃ©pendances
```

---

## ğŸ› ï¸ Technologies utilisÃ©es

### Frontend
- **Streamlit** 1.31 - Interface web
- **Plotly** 5.18 - Graphiques interactifs
- **Matplotlib/Seaborn** - Visualisations

### Machine Learning
- **XGBoost** 2.0 - ModÃ¨le principal
- **LightGBM** 4.1 - ModÃ¨le alternatif
- **scikit-learn** 1.3 - Preprocessing
- **SHAP** 0.44 - ExplicabilitÃ©

### Data Processing
- **Pandas** 2.1 - Manipulation de donnÃ©es
- **NumPy** 1.26 - Calculs numÃ©riques

### Testing
- **pytest** 7.4 - Tests unitaires
- **pytest-cov** 4.1 - Couverture

---

## ğŸš§ Axes d'amÃ©lioration

### Court terme
- [ ] Ajout de sources de donnÃ©es (Indeed, LinkedIn)
- [ ] AmÃ©lioration du modÃ¨le (RÂ² >0.40)
- [ ] Mode sombre et export PDF

### Moyen terme
- [ ] API REST pour prÃ©dictions
- [ ] SystÃ¨me de recommandations de formations
- [ ] DÃ©ploiement cloud (AWS/Streamlit Cloud)

### Long terme
- [ ] NLP avancÃ© (BERT, GPT)
- [ ] PrÃ©diction d'Ã©volution du marchÃ©
- [ ] Plateforme collaborative

---

## ğŸ‘¥ Auteurs

**Emmanuel Paguiel**
- ğŸ“ Etudiant en Economie de l'entreprise


---

## ğŸ™ Remerciements

- **HelloWork.com** pour les donnÃ©es
- **CommunautÃ© Streamlit**
- **Anthropic Claude** pour l'assistance

---

## ğŸ“„ License

MIT License - Copyright (c) 2026 Emmanuel

---
